# Fall Detection System using MLP + CNN

## üìå Gi·ªõi thi·ªáu
H·ªá th·ªëng ph√°t hi·ªán t√© ng√£ s·ª≠ d·ª•ng m√¥ h√¨nh k·∫øt h·ª£p **MLP (Multi-Layer Perceptron) + CNN (Convolutional Neural Network)**. M√¥ h√¨nh n√†y ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n **SisFall Dataset** ƒë·ªÉ nh·∫≠n di·ªán c√°c h√†nh ƒë·ªông t√© ng√£ v√† ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng, gi√∫p h·ªó tr·ª£ gi√°m s√°t s·ª©c kh·ªèe cho ng∆∞·ªùi cao tu·ªïi ho·∫∑c ng∆∞·ªùi c√≥ nguy c∆° t√© ng√£.

## üìÇ Dataset
H·ªá th·ªëng s·ª≠ d·ª•ng **SisFall Dataset**, bao g·ªìm d·ªØ li·ªáu gia t·ªëc v√† con quay h·ªìi chuy·ªÉn ƒë∆∞·ª£c ghi l·∫°i t·ª´ c√°c thi·∫øt b·ªã ƒëeo.

- **SisFall Dataset**: [T·∫£i t·∫°i ƒë√¢y](https://www.kaggle.com/datasets/kushajmallick/sisfalldataset)
- **SisFall Enhanced Dataset (c√≥ nh√£n)**: [T·∫£i t·∫°i ƒë√¢y](https://www.kaggle.com/datasets/nvnikhil0001/sisfall-enhanced)
- Ho·∫∑c c√≥ th·ªÉ t·∫£i b·∫±ng l·ªánh:
  ```bash
  !gdown -q 1-E-TLd5_J-DDWZXkuYL-moMpoezlMn4Z  # SisFall Dataset
  !gdown -q 1gvOuxPc8dNgTnxuvPcVuCKifOf98-TV0  # SisFall Enhanced Dataset (Labels)
  ```

## ‚öôÔ∏è C√†i ƒë·∫∑t
### Y√™u c·∫ßu h·ªá th·ªëng
- Python >= 3.7
- TensorFlow >= 2.0
- NumPy, Pandas, Scikit-learn, Matplotlib

### C√†i ƒë·∫∑t th∆∞ vi·ªán
```bash
pip install numpy pandas scikit-learn matplotlib tensorflow tqdm gdown
```

## üöÄ Tri·ªÉn khai
### 1Ô∏è‚É£ Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
```python
from dataset_processor import DatasetProcessor

# Kh·ªüi t·∫°o b·ªô x·ª≠ l√Ω d·ªØ li·ªáu
dp = DatasetProcessor()

# L·∫•y danh s√°ch file train v√† test
train_files, test_files = dp.get_file_name("/path/to/dataset/")

# Chuy·ªÉn d·ªØ li·ªáu sang numpy array
train_data = dp.datasets_to_nparray(train_files)
test_data = dp.datasets_to_nparray(test_files)
```

### 2Ô∏è‚É£ T·∫°o m√¥ h√¨nh MLP + CNN
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, Dense, Flatten, Dropout, MaxPooling1D

model = Sequential([
    Conv1D(64, kernel_size=3, activation='relu', input_shape=(200, 9)),
    MaxPooling1D(pool_size=2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()
```

### 3Ô∏è‚É£ Hu·∫•n luy·ªán m√¥ h√¨nh
```python
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32)
```

### 4Ô∏è‚É£ ƒê√°nh gi√° m√¥ h√¨nh
```python
eval_result = model.evaluate(X_test, y_test)
print(f"Loss: {eval_result[0]}, Accuracy: {eval_result[1]}")
```

## üìä K·∫øt qu·∫£ mong ƒë·ª£i
- ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p ki·ªÉm tra (**Test Accuracy**) kho·∫£ng **85-95%** t√πy theo c√°ch ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu.
- C√≥ th·ªÉ c·∫£i thi·ªán b·∫±ng c√°ch ƒëi·ªÅu ch·ªânh tham s·ªë m√¥ h√¨nh ho·∫∑c s·ª≠ d·ª•ng k·ªπ thu·∫≠t tƒÉng c∆∞·ªùng d·ªØ li·ªáu (Data Augmentation).


